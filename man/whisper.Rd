% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/whisper.R
\name{whisper}
\alias{whisper}
\title{Automatic Speech Recognition using Whisper}
\usage{
whisper(
  x,
  use_gpu = FALSE,
  flash_attn = TRUE,
  overwrite = FALSE,
  model_dir = Sys.getenv("WHISPER_MODEL_DIR", unset = getwd()),
  ...
)
}
\arguments{
\item{x}{the path to a model, an object returned by \code{\link{whisper_download_model}} or a character string with 
the name of the model which can be passed on to \code{\link{whisper_download_model}}}

\item{use_gpu}{logical indicating to use the GPU in case you have Metal or an NVIDIA GPU. Defaults to \code{FALSE}.}

\item{flash_attn}{logical indicating to use flash attention. Defaults to \code{TRUE}.}

\item{overwrite}{logical indicating to overwrite the model file if the model file was already downloaded, passed on to \code{\link{whisper_download_model}}. Defaults to \code{FALSE}.}

\item{model_dir}{a path where the model will be downloaded to, passed on to \code{\link{whisper_download_model}}. 
Defaults to the environment variable \code{WHISPER_MODEL_DIR} and if this is not set, the current working directory}

\item{...}{further arguments, passed on to the internal C++ function \code{whisper_load_model}}
}
\value{
an object of class \code{whisper} which is list with the following elements: 
\itemize{
\item{file: path to the model}
\item{model: an Rcpp pointer to the loaded Whisper model}
}
}
\description{
Automatic Speech Recognition using Whisper on 16-bit WAV files. Load the speech recognition model.
}
\examples{
\dontrun{ 
## Provide shorthands 'tiny', 'base', 'small', 'medium', ...
model <- whisper("tiny")
trans <- predict(model, newdata = system.file(package = "audio.whisper", "samples", "jfk.wav"))
trans
model <- whisper("base")
trans <- predict(model, newdata = system.file(package = "audio.whisper", "samples", "jfk.wav"))
trans
model <- whisper("small")
trans <- predict(model, newdata = system.file(package = "audio.whisper", "samples", "jfk.wav"))
trans
model <- whisper("medium")
trans <- predict(model, newdata = system.file(package = "audio.whisper", "samples", "jfk.wav"))
trans
model <- whisper("large-v1")
trans <- predict(model, newdata = system.file(package = "audio.whisper", "samples", "jfk.wav"))
trans

## Or download the model explicitely
path  <- whisper_download_model("tiny")
model <- whisper(path)
trans <- predict(model, newdata = system.file(package = "audio.whisper", "samples", "jfk.wav"))
}

## Or provide the path to the model you have downloaded previously
path  <- system.file(package = "audio.whisper", "repo", "ggml-tiny-q5_1.bin")
path
model <- whisper(path)
trans <- predict(model, newdata = system.file(package = "audio.whisper", "samples", "jfk.wav"), 
                 language = "en")
                 
## Add diarization
trans <- predict(model, newdata = system.file(package = "audio.whisper", "samples", "stereo.wav"), 
                 language = "es", diarize = TRUE)
## Provide multiple offsets and durations to get the segments in there
trans <- predict(model, newdata = system.file(package = "audio.whisper", "samples", "stereo.wav"), 
                 language = "es", diarize = TRUE, 
                 offset = c( 650, 6060, 10230), duration = c(4990, 3830, 11650))
## Provide sections - this will make a new audio file and next do the transcription
if(require(data.table) && require(audio)){
trans <- predict(model, newdata = system.file(package = "audio.whisper", "samples", "stereo.wav"), 
                 language = "es", diarize = TRUE, 
                 sections = data.frame(start    = c( 650, 6060, 10230), 
                                       duration = c(4990, 3830, 11650)))
}

\dontshow{
## Or provide the path to the model
path  <- system.file(package = "audio.whisper", "models", "for-tests-ggml-tiny.bin")
model <- whisper(path)
trans <- predict(model, newdata = system.file(package = "audio.whisper", "samples", "jfk.wav"), 
                 language = "en", duration = 1000)
path  <- system.file(package = "audio.whisper", "models", "for-tests-ggml-tiny.en.bin")
model <- whisper(path)
trans <- predict(model, newdata = system.file(package = "audio.whisper", "samples", "jfk.wav"), 
                 language = "en", duration = 1000)
}
}
\seealso{
\code{\link{predict.whisper}}
}
