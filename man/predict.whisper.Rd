% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/whisper.R
\name{predict.whisper}
\alias{predict.whisper}
\title{Transcribe audio files using a Whisper model}
\usage{
\method{predict}{whisper}(
  object,
  newdata,
  type = c("transcribe", "translate"),
  language = "auto",
  trim = FALSE,
  trace = TRUE,
  ...
)
}
\arguments{
\item{object}{a whisper object}

\item{newdata}{the path to a 16-bit .wav file}

\item{type}{character string with the type of prediction, can either be 'transcribe' or 'translate', where 'translate' will put the spoken text in English.}

\item{language}{the language of the audio. Defaults to 'auto'. For a list of all languages the model can handle: see \code{\link{whisper_languages}}.}

\item{trim}{logical indicating to trim leading/trailing white space from the transcription using \code{\link{trimws}}. Defaults to \code{FALSE}.}

\item{trace}{logical indicating to print the trace of the evolution of the transcription. Defaults to \code{TRUE}}

\item{...}{further arguments, directly passed on to the C++ function, for expert usage only and subject to naming changes. See the details.}
}
\value{
an object of class \code{whisper_transcription} which is a list with the following elements:
\itemize{
\item{n_segments: the number of audio segments}
\item{data: a data.frame with the transcription with columns segment, text, from, to and optionally speaker if diarize=TRUE}
\item{tokens: a data.frame with the transcription tokens with columns segment, token_id, token, token_prob indicating the token probability given the context}
\item{params: a list with parameters used for inference}
\item{timing: a list with elements start, end and duration indicating how long it took to do the transcription}
}
}
\description{
Automatic Speech Recognition using Whisper on 16-bit WAV files
}
\details{
\itemize{
\item{offset: milliseconds indicating to start transcribing from that timepoint onwards. Defaults to 0.}
\item{duration: how many milliseconds need to be transcribed. Defaults to the whole audio file.}
\item{token_timestamps: logical indicating to get the timepoints of each token}
\item{n_threads: how many threads to use to make the prediction. Defaults to 1}
\item{prompt: the initial prompt to pass on the model. Defaults to ''}
\item{entropy_thold: entropy threshold for decoder fail. Defaults to 2.4}
\item{logprob_thold: log probability threshold for decoder fail. Defaults to -1}
\item{beam_size: beam size for beam search. Defaults to -1}
\item{best_of: number of best candidates to keep. Defaults to 5}
\item{max_context: maximum number of text context tokens to store. Defaults to -1}
\item{diarize: logical indicating to perform speaker diarization for audio with more than 1 channel}
}
}
\examples{
\donttest{ 
model <- whisper("tiny")
audio <- system.file(package = "audio.whisper", "samples", "jfk.wav")
trans <- predict(model, newdata = audio)
trans <- predict(model, newdata = audio, language = "en")
trans <- predict(model, newdata = audio, language = "en", token_timestamps = TRUE)

audio <- system.file(package = "audio.whisper", "samples", "proficiat.wav")
model <- whisper("tiny")
trans <- predict(model, newdata = audio, language = "nl", type = "transcribe")
model <- whisper("tiny")
trans <- predict(model, newdata = audio, language = "nl", type = "translate")

\dontshow{
if(file.exists(model$file)) file.remove(model$file)
}
}

## Predict using a quantised model
audio <- system.file(package = "audio.whisper", "samples", "jfk.wav")
path  <- system.file(package = "audio.whisper", "repo", "ggml-tiny-q5_1.bin")
model <- whisper(path)
trans <- predict(model, newdata = audio, language = "en", trace = FALSE)
trans <- predict(model, newdata = audio, language = "en", token_timestamps = TRUE)
## Predict using a quantised model with the GPU
model <- whisper(path, use_gpu = TRUE)
trans <- predict(model, newdata = audio, language = "en")
trans <- predict(model, newdata = audio, language = "en", token_timestamps = TRUE)
## Example of providing further arguments to predict.whisper
audio <- system.file(package = "audio.whisper", "samples", "stereo.wav")
trans <- predict(model, newdata = audio, language = "auto", diarize = TRUE)
}
\seealso{
\code{\link{whisper}}, \code{\link{whisper_languages}}
}
